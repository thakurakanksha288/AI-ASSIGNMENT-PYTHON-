{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOljTTIjCabrX0+WHzhlmXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thakurakanksha288/AI-ASSIGNMENT-PYTHON-/blob/main/demo_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VgYBr0EJjpm0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    silhouette_samples,\n",
        "    davies_bouldin_score,\n",
        "    calinski_harabasz_score\n",
        ")\n",
        "\n",
        "from scipy import stats\n",
        "import glob, os, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-darkgrid\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_path):\n",
        "    block_files = glob.glob(os.path.join(data_path, \"block_*.csv\"))\n",
        "    if not block_files:\n",
        "        raise FileNotFoundError(\"No block_*.csv files found\")\n",
        "\n",
        "    energy_data = pd.concat(\n",
        "        [pd.read_csv(f) for f in block_files],\n",
        "        ignore_index=True\n",
        "    )\n",
        "\n",
        "    return energy_data"
      ],
      "metadata": {
        "id": "OHyizZuNjuBX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_features(df):\n",
        "    id_col = next(c for c in df.columns if c.lower() in [\"lclid\",\"building_id\",\"id\",\"meter_id\"])\n",
        "\n",
        "    features = []\n",
        "    for bid in df[id_col].unique():\n",
        "        d = df[df[id_col] == bid]\n",
        "        if len(d) < 10:\n",
        "            continue\n",
        "\n",
        "        energy = d.filter(regex=\"energy|kwh|consumption\", axis=1).iloc[:,0]\n",
        "\n",
        "        features.append({\n",
        "            \"building_id\": bid,\n",
        "            \"mean_consumption\": energy.mean(),\n",
        "            \"max_demand\": energy.max(),\n",
        "            \"std_consumption\": energy.std(),\n",
        "            \"peak_to_avg_ratio\": energy.max() / (energy.mean() + 1e-9),\n",
        "            \"load_factor\": energy.mean() / (energy.max() + 1e-9),\n",
        "            \"total_consumption\": energy.sum(),\n",
        "            \"skewness\": energy.skew(),\n",
        "            \"kurtosis\": energy.kurtosis()\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(features)"
      ],
      "metadata": {
        "id": "nNeLJnG1j-Yk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(features_df):\n",
        "    building_ids = features_df[\"building_id\"]\n",
        "    X = features_df.drop(columns=[\"building_id\"])\n",
        "\n",
        "    X = X.replace([np.inf, -np.inf], np.nan)\n",
        "    X = X.fillna(X.median())\n",
        "\n",
        "    scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, building_ids, X"
      ],
      "metadata": {
        "id": "DiL0-BIzj_Ro"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_pca(X_scaled, variance=0.9):\n",
        "    pca_full = PCA().fit(X_scaled)\n",
        "    n_comp = np.argmax(np.cumsum(pca_full.explained_variance_ratio_) >= variance) + 1\n",
        "\n",
        "    pca = PCA(n_components=n_comp)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    # Scree plot (research standard)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(np.cumsum(pca_full.explained_variance_ratio_), marker=\"o\")\n",
        "    plt.axhline(variance, linestyle=\"--\", color=\"red\")\n",
        "    plt.xlabel(\"Components\")\n",
        "    plt.ylabel(\"Cumulative Variance\")\n",
        "    plt.title(\"PCA Scree Plot\")\n",
        "    plt.show()\n",
        "\n",
        "    return X_pca, pca"
      ],
      "metadata": {
        "id": "sTje-LVdkBNi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_k(X_pca, max_k=10):\n",
        "    ks, sil, inertias = [], [], []\n",
        "\n",
        "    for k in range(2, max_k+1):\n",
        "        km = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
        "        labels = km.fit_predict(X_pca)\n",
        "        ks.append(k)\n",
        "        sil.append(silhouette_score(X_pca, labels))\n",
        "        inertias.append(km.inertia_)\n",
        "\n",
        "    # Research plots\n",
        "    fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
        "    ax[0].plot(ks, inertias, marker=\"o\")\n",
        "    ax[0].set_title(\"Elbow Method\")\n",
        "\n",
        "    ax[1].plot(ks, sil, marker=\"o\")\n",
        "    ax[1].set_title(\"Silhouette Analysis\")\n",
        "    plt.show()\n",
        "\n",
        "    return ks[np.argmax(sil)]"
      ],
      "metadata": {
        "id": "T7MT8q9WkDsI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_kmeans(X_pca, k):\n",
        "    kmeans = KMeans(n_clusters=k, n_init=50, random_state=42)\n",
        "    labels = kmeans.fit_predict(X_pca)\n",
        "\n",
        "    metrics = {\n",
        "        \"silhouette\": silhouette_score(X_pca, labels),\n",
        "        \"davies_bouldin\": davies_bouldin_score(X_pca, labels),\n",
        "        \"calinski_harabasz\": calinski_harabasz_score(X_pca, labels),\n",
        "        \"inertia\": kmeans.inertia_\n",
        "    }\n",
        "\n",
        "    return labels, metrics"
      ],
      "metadata": {
        "id": "9BG-0JYikG7r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_kmeans(X_pca, k):\n",
        "    kmeans = KMeans(n_clusters=k, n_init=50, random_state=42)\n",
        "    labels = kmeans.fit_predict(X_pca)\n",
        "\n",
        "    metrics = {\n",
        "        \"silhouette\": silhouette_score(X_pca, labels),\n",
        "        \"davies_bouldin\": davies_bouldin_score(X_pca, labels),\n",
        "        \"calinski_harabasz\": calinski_harabasz_score(X_pca, labels),\n",
        "        \"inertia\": kmeans.inertia_\n",
        "    }\n",
        "\n",
        "    return labels, metrics"
      ],
      "metadata": {
        "id": "wmtQl0i-kKaT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_clusters(X_original, labels):\n",
        "    df = X_original.copy()\n",
        "    df[\"Cluster\"] = labels\n",
        "\n",
        "    profiles = df.groupby(\"Cluster\").mean()\n",
        "\n",
        "    # Heatmap (research-grade)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.heatmap(profiles.T, cmap=\"RdYlGn_r\", annot=True, fmt=\".2f\")\n",
        "    plt.title(\"Cluster Feature Profiles\")\n",
        "    plt.show()\n",
        "\n",
        "    return profiles"
      ],
      "metadata": {
        "id": "mo8e3nIekMdu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_clusters(X_original, labels):\n",
        "    df = X_original.copy()\n",
        "    df[\"Cluster\"] = labels\n",
        "\n",
        "    profiles = df.groupby(\"Cluster\").mean()\n",
        "\n",
        "    # Heatmap (research-grade)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.heatmap(profiles.T, cmap=\"RdYlGn_r\", annot=True, fmt=\".2f\")\n",
        "    plt.title(\"Cluster Feature Profiles\")\n",
        "    plt.show()\n",
        "\n",
        "    return profiles"
      ],
      "metadata": {
        "id": "zhGY2ekUkOM1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_clusters(X_pca, labels):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.scatter(X_pca[:,0], X_pca[:,1], c=labels, cmap=\"viridis\", s=40)\n",
        "    plt.xlabel(\"PC1\")\n",
        "    plt.ylabel(\"PC2\")\n",
        "    plt.title(\"K-Means Clusters in PCA Space\")\n",
        "    plt.colorbar(label=\"Cluster\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "q8WhbzbjkQio"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(data_path):\n",
        "    data = load_data(data_path)\n",
        "    features = engineer_features(data)\n",
        "    X_scaled, building_ids, X_original = preprocess(features)\n",
        "\n",
        "    X_pca, pca = apply_pca(X_scaled)\n",
        "    optimal_k = find_optimal_k(X_pca)\n",
        "\n",
        "    labels, metrics = apply_kmeans(X_pca, optimal_k)\n",
        "    profiles = analyze_clusters(X_original, labels)\n",
        "    plot_clusters(X_pca, labels)\n",
        "\n",
        "    print(\"\\nFinal Clustering Metrics:\")\n",
        "    for k,v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "m6ggEQ2PkSQt"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}